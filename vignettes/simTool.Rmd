%\VignetteIndexEntry{simTool}
%\VignetteEngine{knitr::knitr}
---
title: "simTool"
author: "Marsel Scheer"
date: "24.08.2014"
output:
  html_document:
    number_sections: yes
    toc: yes
---

# Introduction

The purpose of the *simTool* package is to disengage the research from any kind
of administrative source code which is usually an annoying necessity of a 
simulation study.

This vignette will give an introduction into the *simTool* package mainly by
examples of growing complexity. The workhorse is the function *evalGrids*. Every
parameter of this function will be discussed briefly and the functionality is
illustrated by at least one example.

# Workflow

The workflow is quite easy and natural. One defines two *data.frames*, the first
one represents the functions that generate the data sets and the second one represents
the functions that analyze the data. These two *data.frames* are passed to
*evalGrids* which conducts the simulation. Afterwards, the results can nicely
be displayed as a *data.frame* be coercing the object returned by *evalGrids*
to a *data.frame*.

# Defining the *data.frames* for data generation and analyzation

There are 3 rules:

* the first column ( a *character* vector) defines the functions to be called
* the other columns are the parameters that are passed to function specified in the first column
* The entry *NA* will not be passed to the function specified in the first column.

The function *expandGrid* is a convenient function for defining such *data.frames*.

We now define the data generation functions for our first simulation.
```{r}
library(simTool)
library(plyr)
library(reshape)
print(dg <- rbind.fill(
  expandGrid(fun="rexp", n=c(10, 20), rate=1:2),
  expandGrid(fun="rnorm", n=c(10, 20), mean=1:2)))
```


This *data.frame* represents 8 *R*-functions. For instance, the second
row represents a function that generates 20 exponential distributed random variables
with *rate* 1. Since *mean=NA* in the second row, this parameter is
not passed to *rexp*.

Similar, we define the *data.frame* for data analyzing functions.

```{r}
print(pg<-rbind.fill(
  expandGrid(proc="min"),
  expandGrid(proc="mean", trim=c(0.1, 0.2))))
```

Hence, this *data.frame* represents 3 *R*-functions i.e. calculating the
minimum and the arithmetic mean with *trim=0.1* and *trim=0.2*.

# The workhorse *evalGrids*

The workhorse *evalGrids* has the following simplified pseudo code:


```{r, eval=FALSE}
1.  convert dg to R-functions  {g_1, ..., g_k} 
2.  convert pg to R-functions  {f_1, ..., f_L} 
3.  initialize result object 
4.  append dg and pg to the result object 
5.  t1 = current.time() 
6.  for g in  {g_1, ..., g_k} 
7.      for r in 1:replications (optionally in a parallel manner) 
8.          data = g() 
9.          for f in  {f_1, \ldots, f_L} 
10.             append f(data) to the result object 
11.         optionally append data to the result object 
12.      optionally summarize the result object over all  
         replications but separately for f_1, ..., f_L
13.     optionally save the results so far obtained to HDD  
14. t2 = current.time() 
15. Estimate the number of replications per hour from t1 and t2 
```

In general, the object returned by *evalGrids* is a *list*
of class *evalGrid* and can be coerced into 
a *data.frame*. Later on, we will investigate the case if this is
not the case.

```{r}
dg = expandGrid(fun="rnorm", n=10, mean=1:2)
pg = expandGrid(proc="min")
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 2)
as.data.frame(eg)
```

As you can see, the function always estimates the number of replications that can be
done in one hour. 

The object returned by *evalGrids* will be discussed at the
end of this section. But specific points about this object will
be explained earlier.

## Parameter *replications*

Of course, this parameter controls the number of replications conducted.
```{r}
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 3)
as.data.frame(eg)
```

## Parameter *discardGeneratedData*

*evalGrids* saves ALL generated data sets.
In general, it is sometimes very handy to
have the data sets in order to investigate unusual or unexpected results.
But saving the generated data sets can be very memory consuming.
Stop saving the generated data sets can be obtained by setting 
*discardGeneratedData = TRUE*.
Confer command line 11 in the pseudo code.
```{r}
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000)
object.size(eg)
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000,
    discardGeneratedData = TRUE)
object.size(eg)
```
The object returned by *evalGrids* will be discussed at the
end of this vignette.

## Parameter *progress*

This parameter activates a text progress bar in the console. Usually,
this does not make sense if one uses *Sweave* or *knitr*,
but for demonstration purpose we do this here.

```{r}
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 10,
    progress = TRUE)
``` 

The progress bar increases every time a new element is chosen in
command line 6 of the pseudo code.

## Parameter *post.proc*

As stated in command line 12 we can summarize the result objects over 
all replications but separately for all data analyzing functions.
```{r}
dg = expandGrid(fun="runif", n=c(10,20,30))
pg = expandGrid(proc=c("min", "max"))
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000, 
    post.proc=mean)
as.data.frame(eg)
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000, 
    post.proc=c(mean, sd))
as.data.frame(eg)
```
Note, by specifying the parameter *post.proc* the generated data sets
and all individual result objects are discarded. In this example we discard
$3 \times 1000$ data sets and $3 \times 1000 \times 2$ individual result
objects. Although the function *as.data.frame* or to be more precise
*as.data.frame.evalGrid* has also a parameter *post.proc* that
serves the same purpose, it may be necessary to summarize the results as soon
as possible to spare memory. 

We now briefly show that *post.proc* in *evalGrids* and
*as.data.frame* yield the same results.

```{r}
set.seed(1234)
# summarize the result objects as soon as possible
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000, 
    post.proc=mean)
as.data.frame(eg)
set.seed(1234)
# keeping the result objects
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 1000)
# summarize the result objects by as.data.frame
as.data.frame(eg, post.proc=mean)
```

## Parameter *ncpus* and *clusterSeed*

By specifying *ncpus* larger than 1 a cluster objected is created
for the user and passed to the parameter *cluster* discussed in the
next section.
```{r}
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 10, 
    ncpus=2, post.proc=mean)
as.data.frame(eg)
```
As it is stated in command line 6, the replications are parallelized. In our case, this means
that roughly every CPU conducts 5 replications.

The parameter *clusterSeed* must be an integer vector of length 6 and
serves the same purpose as the function *set.seed*. By default,
*clusterSeed* equals *rep(12345, 6)*. Note, in order
to reproduce the simulation study it is also necessary that *ncpus*
does not change.

## Parameter *cluster*
The user can create a cluster on its own. This also enables the user
to distribute the replications over different computers in a network.
```{r}
require(parallel)
cl = makeCluster(rep("localhost", 2), type="PSOCK") 
eg = evalGrids(dataGrid = dg, procGrid = pg, replications = 10, 
    cluster=cl, post.proc=mean)
as.data.frame(eg)
stopCluster(cl)
```
As you can see our cluster consists of 3 workers. Hence, this reproduces the
results from the last code chunk above. Further note, if the user starts the
cluster, the user also has to stop the cluster. A cluster that is created
within *evalGrids* by specifying *ncpus* is also stop within
*evalGrids*.

## Parameter *clusterLibraries* and *clusterGlobalObjects*

A newly created cluster is ``empty''. Hence, if the simulation study requires
libraries or objects from the global environment, they must be transferred to 
the cluster.

Lets look at standard example from the *boot* package.
```{r}
library(boot)
ratio <- function(d, w) sum(d$x * w)/sum(d$u * w)
city.boot <- boot(city, ratio, R = 999, stype = "w", 
    sim = "ordinary")
boot.ci(city.boot, conf = c(0.90, 0.95),
    type = c("norm", "basic", "perc", "bca"))
```

The following data generating function is extremely boring because it always returns
the data set *city* from the library *boot*.
```{r}
returnCity = function(){
  city
}
bootConfInt = function(data){
city.boot <- boot(data, ratio, R = 999, stype = "w", 
    sim = "ordinary")
boot.ci(city.boot, conf = c(0.90, 0.95),
    type = c("norm", "basic", "perc", "bca"))  
}
```

The function *ratio* exists at the moment only in our global environment.
Further we had to load the *boot* package. Hence, we load the *boot*
package by setting *clusterLibraries = c("boot")* and transfer the function
*ratio* by setting *clusterGlobalObjects = c("ratio")*.

```{r}
dg = expandGrid(fun="returnCity")
pg = expandGrid(proc="bootConfInt")
eg = evalGrids(dg, pg, replications=10, ncpus=2,
    clusterLibraries=c("boot"), 
    clusterGlobalObjects=c("ratio"))
```

Of course, it is possible to set *clusterGlobalObjects=ls()*, but then 
all objects from the global environment are transferred to all workers.

## Parameter *fallback*

If the user is afraid of a power black out, server crashes, or something else interrupting
the simulation study, the user can pass a character to *fallback*. Then every
time a new element in command line 6 is chosen, the results obtained so far are written
to the file specified in *fallback*. 

```{r}
genData = function(n){
  n
}
anaData = function(data){
  if (data == 4) 
    stop("Simulated error that terminates the simulation")
  data^2
}
dg = expandGrid(fun="genData", n=1:5)
pg = expandGrid(proc="anaData")
try(eg <- evalGrids(dg, pg, replications=2, 
    fallback="simTool_fbTest"))
```

Loading the *Rdata*-file creates an *R*-object *fallBackObj*
of the class *evalGrid*. Of course, some results are missing 
which is indicated by the column \linebreak *.evalGridComment* in the 
resulting *data.frame*.

```{r}
# clean the current R-session
rm(list=ls())
load("simTool_fbTest.Rdata")
as.data.frame(fallBackObj)
```

## Parameter *envir*

The function *evalGrids* generates in a
first step function calls from *dataGrid*
and *procGrid*. This is achieved by applying
the *R*-function
*get*. By default, *envir=globalenv()*
and thus *get* 
searches the global environment of the
current R session. An example shows how to use
the parameter *envir*.
```{r}
# masking summary from the base package
summary = function(x) sd(x) 
g = function(x) quantile(x, 0.1)
someFunc = function(){
  summary = function(x) c(sd=sd(x), mean=mean(x))
  
  dg = expandGrid(fun="runif", n=100)
  pg = expandGrid(proc=c("summary", "g"))

  # the standard is to use the global
  # environment, hence summary defined outside
  # of someFunc() will be used
  print(as.data.frame(evalGrids(dg, pg)))
  cat("--------------------------------------------------\n")
  # will use the local defined summary, but g
  # from the global environment, because
  # g is not locally defined.
  print(as.data.frame(evalGrids(dg, pg, envir=environment())))
}
someFunc()
```


## The result object
Usually, the user has not work with the object returned by *evalGrids* because
*as.data.frame* can coerce it to a *data.frame*. Nevertheless,
we want to discuss the return value of *evalGrids*.
```{r}
dg = rbind.fill(
  expandGrid(fun="rexp", n=c(10, 20), rate=1:2),
  expandGrid(fun="rnorm", n=c(10, 20), mean=1:2))
pg = rbind.fill(
  expandGrid(proc="min"),
  expandGrid(proc="mean", trim=c(0.1, 0.2)))
```

Now we conduct a simulation study and discuss the result object
```{r}
eg = evalGrids(dg, pg, replications=100)
```
The returned object is a *list* of class *evalGrid*:
```{r}
names(eg)
```
The important element is *simulation*
which itself is a *list*. It optionally contains ALL data that were generated and optionally
contains ALL objects returned by the data analyzing functions. The structure is as follows.
*eg\$simulation[[i]][[r]]\$data* is the data generated by the $i$th row in *dg*
in the $r$th replication and *eg\$simulation[[i]][[r]]\$results[[j]]* is the object
returned by the $j$th parameter constellation of *pg* applied to \linebreak
*eg\$simulation[[i]][[r]]\$data*. For instance, let $i=7, r=22$, and $j=3$. We generated
the data according to 
```{r}
dg[7,]
```
that is \Sexpr{dg[7,"n"]} normal distributed random variables with mean \Sexpr{dg[7,"mean"]}
and analyzed it with
```{r}
pg[3,]
```
In the 22nd replication this leads to
```{r}
eg$simulation[[7]][[22]]$results[[3]]
```
which can be replicated by
```{r}
mean(eg$simulation[[7]][[22]]$data, trim=0.2)
```

# Converting results to *data.frame*

We have already applied *as.data.frame.evalGrid* many times. This function
also has the parameters *post.proc* and *progress*. The functionality
of these parameter resembles the corresponding parameters of *evalGrids*.
Hence, it remains to explain *value.fun*. Sometimes, the objects returned by
the analyzing functions can not be automatically converted to *data.frame*.
In such cases, the parameter *value.fun* enables the user to pre-process
the result objects. We exemplify this by calculating linear regression models.

```{r}
genRegData <- function(){
  data.frame(
    x = 1:10,
    y = rnorm(10, mean=1:10))
}
```                                                                                                     

```{r}
eg <- evalGrids(
  expandGrid(fun="genRegData"),
  expandGrid(proc="lm", formula=c("y ~ x", "y ~ x + I(x^2)")),
  replications=100)
class(eg$simulation[[1]][[1]]$results[[1]])
``` 
An object of class *lm* can easily be converted by
calling *coef*.
```{r}
head(df<-as.data.frame(eg, value.fun=coef))
```
Of course, this can be combined with *post.proc*
```{r}
as.data.frame(eg, value.fun=coef, post.proc=c(mean, sd))
```
